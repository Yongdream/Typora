

[TOC]

# `WebServer`

## 项目介绍

webserver项目是我学习计算机网络知识和Linux socket编程中开发的轻量级服务器项目。整个网络模型是主从Reactor加线程池的方案。具备处理多个http和ftp协议的能力，同时还能提供轻量化的存储。

最后的压力测试，最后是部署到云端服务器上的，在2核的服务器上，通过webbench测试下，存储引擎操作的读写QPS（每秒查询率）都有30多万。

### muduo集群聊天器

使用muduo网络库搭建网络核心模块、Nginx实现聊天服务器的集群，提高并发能力、Redis作为消息中间件、MySQL作为数据存储、json序列化和反序列化作为通信协议的实时聊天服务器。

1. 使用muduo网络库作为项目的网络核心模块，提供高并发网络IO服务，解耦网络和业务模块代码；
2. 使用json序列化和反序列化消息作为私有通信协议；
3. 配置nginx基于tcp的负载均衡，实现聊天服务器的集群功能，提高后端服务的并发能力；
4. 基于redis的发布-订阅功能，实现跨服务器的消息通信；
5. 使用mysql关系型数据库作为项目数据的落地存储；
6. 使用连接池提高数据库的数据存取功能。

![image-20240727174439283](./typora_photo/Webserver/image-20240727174439283.png)

## 和普通的web服务器的不同改进之处

小顶堆

小顶堆是一种完全二叉树，满足以下性质：每个节点的值都小于或等于其子节点的值。这样，堆顶（根节点）总是最小的元素。

**优先队列**：小顶堆常用于实现优先队列，可以快速 **获取最小值** 并进行插入和删除操作。

**排序**：可以通过堆排序算法进行排序，先将数据构建为小顶堆，然后依次取出堆顶元素进行排序。

## 1.阻塞/非阻塞 同步/异步

阻塞和非阻塞、同步和异步都是描述IO的一个状态，一个典型的网络IO包含两个阶段：数据准备（阻塞和非阻塞）和数据读写（同步和异步）。

以一个套接字文件描述符==sockfd==举例，通过==recv()==从已连接的套接字中接受数据，传入==buf==。

- **阻塞模式**

  调用recv()时，数据若没有就绪，recv会阻塞当前线程；

- **非阻塞**

  调用==recv()==时，数据若没有就绪，立即返回==错误码EAGAIN（不同系统可能不同）==，表示操作没法完成，因为数据没准备好。线程可以继续执行其他操作，而不需要等待数据的到达。

  当数据就绪好了，可以再次调用==recv()==读取数据。

- **同步**

  ==recv()==**一直等待数据**，完全复制到缓存区buf，无法执行其他操作；

- **异步**

  允许应用程序在发起IO请求后，可以继续执行操作。当数据拷贝完成时，通过信号或回调==通知==应用程序。

  使用异步IO接口时，调用函数指定`sockfd`和目标缓冲区`buf`;

  操作完成时，sigio信号或者回调**通知**时候buf数据已经拷贝好了。

  ```cpp
  while (true) {
      int nfds = epoll_wait(epollfd, events, MAX_EVENTS, -1);
      for (int i = 0; i < nfds; ++i) {
          if (events[i].events & EPOLLIN) {
              ssize_t bytes_received = recv(events[i].data.fd, buf, sizeof(buf) - 1, 0);
              buf[bytes_received] = '\0';
              std::cout << "Received: " << buf << std::endl;
          }
      }
  }
  ```

## 2.0 Unix/Linux上的5种IO模型

1. **阻塞IO（Blocking I/O）**

   在阻塞IO模型中，当用户程序调用IO操作（如`recv()`）时，如果数据没有准备好，调用会阻塞，线程会等待数据准备好并完成数据拷贝。整个过程中，线程会一直等待，直到操作完成。

2. **非阻塞IO(Non-Blocking I/O)**

   在非阻塞IO模型中，当用户程序调用IO操作（如`recv()`）时，如果数据没有准备好，调用会立即返回一个错误（如`EAGAIN`），而不会阻塞线程。线程可以继续执行其他操作，并在适当的时候再次尝试IO操作。

3. **`IO多路复用`**

   使用一个进程来维护多个Socket连接。IO多路复用使用系统调用（如`select()`、`poll()`或`epoll()`）来监视多个文件描述符（如套接字）。当任何一个文件描述符就绪时，系统调用会返回，用户程序可以进行相应的IO操作。

   适合处理多个IO操作，避免了轮询多个文件描述符的开销，但**本质上仍然是同步IO**，因为在就绪事件通知后，用户程序仍需负责数据拷贝。

   **<a href="##epoll是同步的还是异步的">🔗epoll是同步的还是异步的</a>**

   **<a href="##9.epoll|为什么使用epoll">🔗epoll，select，poll对比</a>**

4. **信号驱动IO（Signal-Driven I/O）**

   **异步通知，同步数据拷贝**。

   在信号驱动IO模型中，用户程序首先通过设置信号处理程序（如`sigaction()`）来**注册信号处理函数**，并将套接字设置为非阻塞模式和信号驱动模式（使用`fcntl()`设置`O_ASYNC`标志）。

   当数据准备好时，内核会发送一个信号（如`SIGIO`）给用户程序，通知其可以进行IO操作。

5. **异步IO**

   **完全异步**

   在异步IO模型中，用户程序发起IO请求后可以**立即继续执行其他操作**。当IO操作完成（包括数据拷贝）时，内核会通知用户程序（通过信号或回调函数），此时数据已经准备好，用户程序可以直接处理数据。

![image-20240728203028062](./typora_photo/Webserver/image-20240728203028062.png)

### 总结

**同步IO（阻塞IO、非阻塞IO、IO多路复用、信号驱动的数据拷贝）**：

- **通知方式**：这些模型都使用==就绪事件通知方案==，即通知用户程序数据已经准备好。
- **数据拷贝**：用户程序需要负责将数据从内核缓冲区拷贝到用户缓冲区，或者将数据从用户缓冲区拷贝到内核缓冲区。
- **等待时间**：用户程序需要等待数据拷贝完成，这段时间是同步的。

**异步IO（异步/信号驱动的异步通知）**：

- **通知方式**：通知的是事件完成，即数据已经拷贝完毕，用户程序可以立即进行下一步处理。
- **数据拷贝**：由内核负责完成数据拷贝，用户程序不需要等待数据拷贝时间。
- **效率**：更高，因为用户程序可以在IO操作进行时执行其他任务，最大化利用CPU时间。

## 2.1 IO多路复用技术

一种高效的IO处理方式，允许单个线程同时管理多个IO通道，避免了创建多个线程的开销。网络编程中：使用一个进程来维护监听**多个Socket**的方式。

一个进程虽然任意时刻只能处理一个请求，如果每个请求事件的耗时控股之在1ms内，则1s就可以处理上千条请求，把时间拉长看，就是多个请求复用了一个进程，这就是多路复用。这种思想很类似与一个CPU并发多个进程，所以也叫**时分多路复用**。

Linux内核中提供了**`select/poll/epoll`**这三个多路复用的系统调用，进程可以通过一个系统调用函数**从内核中获取多个事件。**

**原理：**`select/poll/epoll`在获取事件时，先把所有的连接（文件描述符，如Socket连接）传给内核，将多个IO事件添加到一个事件集合中进行监听。再由内核返回产生了事件的连接，然后在**用户态**中再处理这些连接对应的请求。

## 2.2 IO多路复用技术|流程

1. 创建Socket文件描述符，并将需要监听的IO事件添加到事件集合中
2. 调用IO多路复用函数，将所有待处理事件的集合传递给函数
3. IO多路复用函数会`等待并监听`**所有传递的事件集合中的IO事件**，并自动挂起当前进程，直到有事件发生或超时
4. 当某个IO事件触发时，IO多路复用函数会返回该事件的文件描述符，并从事件集合中删除该事件
5. 处理完该事件后，将该事件重新加入事件集合中。循环2-5step

## 3.WebServer的作用

一个WebServer就是一个服务器软件。主要功能是通过HTTP协议与客户端（通常是浏览器）进行通信，来接受，存储，处理来自客户端的HTTP请求，并对其请求做出HTTP响应，返回给客户端其请求的内容或返回ERROR信息，最后实现了上万的并发连接。

![image-20240727222355121](./typora_photo/Webserver/image-20240727222355121.png)

## 4.HTTP协议（应用层协议）

<a href="##HTTP | 超文本传输协议，Hypertext Transfer Protocol">HTTP汇总</a>

## 4.HTTP协议|http请求怎么解析的 平时常用的正则表示式

在Web服务器项目中，HTTP请求解析通常涉及以下步骤：

1. **接收请求**

服务器监听特定端口，接收来自客户端的HTTP请求。

2. **解析请求行**

请求行包含请求方法、URI和HTTP版本，例如：
```
GET /index.html HTTP/1.1
```
**正则表达式**：
```regex
^(GET|POST|PUT|DELETE|HEAD|OPTIONS|PATCH) (\S+) HTTP\/(\d+\.\d+)$
```

3. **解析请求头**

请求头包含多个键值对，例如：
```
Host: www.example.com
User-Agent: curl/7.64.1
```
**正则表达式**：
```regex
^([a-zA-Z0-9-]+): (.+)$
```

4. **解析请求体**

对于POST请求，请求体的解析依赖于`Content-Type`，常见类型有`application/json`和`application/x-www-form-urlencoded`。

## 4.HTTP协议|浏览器地址栏键入URL，按下回车之后会经历什么

1. 解析URL，生成发给WEB服务器的HTTP请求
2. 查询服务器域名对应的IP地址，如果缓存中有对应域名缓存，就直接返回；没有，向DNS服务器请求解析该URL中域名所对应的IP地址
3. 解析出IP地址后，就可以把HTTP的传输工作交给操作系统的==协议栈==；
4. 根据IP地址和默认端口80，和服务器建立TCP连接；
5. 浏览器发出读写文件（URL中域名后面部分对应的文件）的HTTP请求，该请求作为TCP三次握手的第三个报文数据发送给服务器；
6. 服务器对浏览器请求做出响应，并把对应的资源发送给浏览器
7. 完成以上过程后，数据已经到达浏览器端，接下来浏览器解析并渲染数据
8. 释放TCP连接。

> HTTP协议是基于TCP/IP协议之上的应用层协议，基于**请求-响应**的模式。HTTP协议规定请求从客户端发出，最后服务器端响应该请求并返回。  
>
> 协议栈上半部分是TCP/UDP协议，执行收发数据的操作；下半部分是IP协议，控制网络包的收发

## 5.日志系统

在这种多生产者、单消费者的日志系统中，确实需要精心设计缓冲区的同步机制，以确保并发性能。以下是实现思路的简要概述：

1. **缓冲区设计**：
   - 使用环形缓冲区（Circular Buffer）来存储日志信息，避免频繁的内存分配。
   - 设置一个**固定大小的缓冲区**，确保在高并发时能有效地管理空间。

2. **同步机制**：
   - 使用互斥锁（Mutex）保护对缓冲区的写入和读取操作，确保数据一致性。
   - 使用条件变量（Condition Variable）来实现生产者与消费者之间的通知机制。生产者在写满缓冲区时阻塞，而消费者在缓冲区为空时阻塞。

3. **多线程设计**：
   - 每个生产者线程独立写入缓冲区，并在写入完成后通知消费者。
   - 单个消费者线程持续从缓冲区读取数据并写入文件，同时保持与生产者的同步。

4. **日志等级管理**：
   - 在日志记录时，生产者可以根据不同的日志等级（如DEBUG、INFO等）选择性写入缓冲区。
   - 消费者则可以根据需要处理特定等级的日志。

5. **异常处理**：
   - 考虑到写文件时可能出现的错误，如磁盘空间不足，消费者需要有相应的异常处理机制。

通过这种设计，生产者与消费者可以并发执行，提高日志记录的效率，同时保持数据的一致性和完整性。

![image-20240923225225294](./typora_photo/Webserver/image-20240923225225294.png)

## 6.两种高效的事件处理模式|Reactor高并发

IO多路复用监听事件，收到事件后，根据事件类型分配给某个进程/线程。有多种的实现方式

![在这里插入图片描述](./typora_photo/Webserver/e0029a69ac754dea95ef6a81eca5f490.png)

### Reactor模式核心组成部分：

1. **Reactor**：负责监听和分发I/O事件，包括连接事件/读写事件。

2. **处理资源池**：可以是进程或线程，负责实际处理事件。

**方案**

- **单Reactor单进程/线程**：一个Reactor在单个进程或线程中处理所有事件。
- **单Reactor多进程/线程**：一个Reactor分发事件到多个进程或线程。
- **多Reactor多进程/线程**：多个Reactor分布在不同的进程或线程中，每个Reactor处理一部分事件。

其中Reactor负责监听和分发事件；Acceptor负责获取连接；Handler负责处理业务逻辑

### 单Reactor单进程/线程（单单，单线程模型）

<img src="./typora_photo/Webserver/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p-P5rK5,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center-1721222159204-15.png" alt="img" style="zoom:33%;" />

1. Reactor通过IO多路复用接口监听事件，根据事件的类型决定**分发**给Acceptor还是Handler处理；

2. 若是**连接建立**的事件，则交给**Acceptor**对象处理，Acceptor对象会通过accept系统调用来获取连接，并建立一个Handler对象来处理后续的响应事件；

3. 若**不是连接建立事件**，则交由**当前连接对应的Handler**对象来进行响应；

4. Handler对象通过r**ead->业务处理->send**的流程来完成完整的业务流程

- **优点**：实现简单，无需考虑进程间通信和多进程竞争。
- **缺点**：无法充分利用多核CPU；Handler在进行业务处理时候，整个进程无法连接其他事件。例如，长耗时业务，响应将会延迟。
### 单Reactor多进程/线程（单多，多线程模型）

<img src="./typora_photo/Webserver/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p-P5rK5,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center.png" alt="在这里插入图片描述" style="zoom: 33%;" />

Reactor通过IO多路复用接口监听事件和**单Reactor单进程**（1-3）一致

4. Handler对象**`不再负责业务逻辑的处理，只负责数据的接受和发送`**。Handler对象通过 **read读取数据** 后，会将数据发送给**线程池中子线程里的`processor对象`**进行业务处理；
5. 子线程里的processor对象处理完后，会将结果发送给**主线程中的Handler对象**，再通过send方法将响应发给client。

- **优点**： 能充分利用多核CPU性能 
- **缺点**：一个Reactor承担所有事件的监听和响应，而只在主线程中进行。随间高并发场景中，无法及时处理新连接、就绪的 IO 事件以及事件转发等。

### 多Reactor多进程/线程（多多，主从多线程模型）

<img src="./typora_photo/Webserver/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p-P5rK5,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center-1721222381763-18.png" alt="在这里插入图片描述" style="zoom: 25%;" />

<img src="./typora_photo/Webserver/主从Reactor多线程.png" alt="多 Reactor 多进程 / 线程方案的示意图" style="zoom: 67%;" />

1. 主线程中的 **`MainReactor`** 对象通过IO多路复用接口**监听连接建立事件**，收到事件后通过Acceptor对象中的accept获取连接，将新的连接分配某个子线程；
2. 子线程中的 **`SubReactor`** 负责后续的读写事件。每个子线程管理自己的一组连接，并且通过**创建** **`Handler`** 处理**数据的读写以及业务逻辑**；
3. 如果有新的事件发生，SubReactor通知当前连接对应的Handler对象来进行响应；
4. Handler对象通过 `read->业务处理->send` 的流程来完成完整的业务逻辑。

- 实现简单，主线程子线程分工明确，主线程子线程交互简单。

## 6.两种高效的事件处理模式|Reactor和Proactor的好处和坏处

Reactor 和 Proactor 是两种常用的 **`并发设计模式`** ，用于处理 I/O 多路复用，特别是在高性能服务器和网络编程中

- **Reactor 模式**

  **非阻塞同步网络模式**，感知的是就绪可读写的信号：主要用于同步 I/O 操作。它依赖于事件分发器（Event Demultiplexer），如 `select`、`poll` 或 `epoll`，来监视多个 I/O 事件并分发到相应的事件处理程序（Event Handler）。

  - 优点
    1. Reactor实现相对简单，对于耗时短的处理场景处理⾼效  
    2. 简单易懂。Reactor模式更简单易懂，容易实现和维护  
  - 缺点
    1. **单线程瓶颈** 在并发度很⾼场景，`单个线程负责监听和分发所有的IO事件`，可能会成为性能瓶颈。
    2. **同步 I/O 操作阻塞** 处理时间较长的任务可能会阻塞事件处理程序，降低系统响应速度。

- **Proactor 模式**

  **异步网络模式**，感知的是已完成的读写信号：主要用于异步 I/O 操作。它将 I/O 操作的处理从应用程序中解放出来，由**操作系统或 I/O 库完成**，**需要传入数据缓冲区的地址等信息，⽤来存放结果数据** 。当 I/O 读写操作完成时，操作系统会通知应用程序，并将结果传递给相应的事件处理程序。

  - 优点
    1. **异步 I/O 特性** 高并发和高负载情况下，异步 I/O 操作可以`避免阻塞`，提高 I/O 操作的并发度
    2. **处理长时间运行的任务** 如大规模数据传输和文件复制等操作。
  - 缺点
    1. **实现较为困难** 需要处理复杂的异步编程模型
    2. **小规模任务的处理效率略低** 需要进行线程切换和上下文切换，额外的开销可能会影响任务的处理效率

## 6.两种高效的事件处理模式|使用 Reactor 方案而不是Proactor？为什么不用异步方案？

- Linux 对 Proactor 支持不足，异步 I/O 支持不完善

  **异步 I/O 的局限性** Linux 虽然有 AIO（Asynchronous I/O）接口，这些接口主要用于本地文件系统，`不是在内核级别实现的真正异步 I/O`，网络socket就不适用。

- `epoll` 等高效 I/O 多路复用机制

  **内核支持** Linux 提供了高效的 I/O 多路复用机制，如 `epoll`、`select` 和 `poll`，这些机制在内核级别实现，能够高效地监视大量文件描述符（包括网络 socket）。这些 I/O 多路复用机制非常适合Reactor 模式

- CPU多核心和优秀线程调度算法也可能与异步操作的性能差不多

## 7.线程池|手写线程池

1. **主线程**：
   - 负责监听和处理I/O事件，使用`epoll_wait`监测可读事件。
   - 当发现某个文件描述符上有可读事件时，主线程会将相应的HTTP请求报文读取到该连接的读缓存中。
   - 将读取到的任务对象插入到线程池的任务队列中。
2. **线程池**：
   - 线程池中的线程负责从任务队列中获取任务，并处理请求逻辑。
   - 线程通过竞争锁资源来获取任务，从而完成报文解析。

```cpp
class ThreadPool {
public:
    ThreadPool(size_t numThreads);	// 构造函数，创建指定数量的工作线程
    ~ThreadPool();	// 析构函数，等待所有线程完成工作
    
    template<class F>	// 添加任务到任务队列
    void enqueue(F&& f);

private:
    // 工作线程执行的函数
    void worker();
    
    std::vector<std::thread> workers;                      // 工作线程
    std::queue<std::function<void()>> tasks;               // 任务队列
    std::mutex queueMutex;                                  // 互斥锁，保护任务队列
    std::condition_variable condition;                       // 条件变量，用于线程同步
    bool stop;                                              // 停止标志
};

ThreadPool::ThreadPool(size_t numThreads) : stop(false) {	// 创建并启动工作线程
    for (size_t i = 0; i < numThreads; ++i) {
        workers.emplace_back([this] { this->worker(); });
    }
}

ThreadPool::~ThreadPool() {
    {
        std::unique_lock<std::mutex> lock(queueMutex);
        stop = true; // 设置停止标志
    }
    condition.notify_all(); // 通知所有线程停止
    for (std::thread& worker : workers) {
        worker.join(); // 等待所有线程结束
    }
}

template<class F>
void ThreadPool::enqueue(F&& f) {
    {
        std::unique_lock<std::mutex> lock(queueMutex);
        tasks.emplace(std::forward<F>(f)); // 将任务添加到队列
    }
    condition.notify_one(); // 唤醒一个工作线程
}

void ThreadPool::worker() {
    while (true) {
        std::function<void()> task;
        {
            std::unique_lock<std::mutex> lock(queueMutex);
            // 等待任务或停止信号
            condition.wait(lock, [this] { return stop || !tasks.empty(); });
            if (stop && tasks.empty()) return; // 停止并且没有任务时退出
            task = std::move(tasks.front()); // 获取任务
            tasks.pop(); // 从队列中移除任务
        }
        task(); // 执行任务
    }
}
```

## 7.线程池|线程池和任务队列有没有做分离

**关系**：任务队列存储待处理的任务，而线程池管理执行这些任务的线程。任务被放入队列后，线程池中的线程从队列中获取任务并并发执行，确保资源的高效利用

有的。主要是为了提升资源的利用率和系统的响应能力，同时也有利于线程安全。**线程池负责生成和管理线程，任务队列用于存储任务**。线程池从任务队列中提取任务，到一个线程中去执行，有任务就执行，无任务阻塞线程休眠。

## 7.线程池|线程池中怎么利用信号量机制 判断线程的空闲状态

1. **初始化，线程阻塞**：线程池中的线程通过run方法从任务队列中提取任务，初始化信号量值为0。由于信号量的初始值为0，在尝试执行任务之前会执行一个等待（wait）操作，这会导致它们阻塞，直到有任务可用。
2. **任务提交**，**信号量增加，唤醒线程**：线程将任务提交到任务队列，并调用线程池的`append`方法。这个方法将**任务添加到队列中**，执行post做一个**V操作**（通常对应于`sem_post`函数），增加+1信号量，`至少有一个等待的线程会被唤醒`。这个线程会从**阻塞状态转换到就绪状态。**
3. **执行任务：**执行前P操作，减少信号量的值。使得**信号量-1**，然后从任务队列中取出任务执行。
4. **循环等待：**如果信号量的值大于0，线程可以继续从队列中获取新任务；如果信号量的值为0，线程将再次执行等待操作，进入阻塞状态

## 7.线程池|为什么要使用线程池

假设一个 Web 服务器需要处理大量的客户端请求。如果每个请求都创建一个新线程来处理，会导致以下问题：

- 大量线程创建和销毁的开销会影响服务器性能。
- 系统资源可能会被过多的线程耗尽，导致服务器崩溃。

**`是什么`**

- 线程池就是一个 pthread_t 类型的普通数组，通过空间换时间的方式，消耗硬件资源，换取运行效率。他是指一组线程资源的集合；

**1）减少线程创建和销毁的开销**  `创建和销毁线程`是⼀项开销较大的操作。线程池在应用启动时**预先创建一个固定数量的线程来处理请求**，而不是在每次需要时动态创建和销毁。这减少了系统在创建和销毁线程时的开销，提升了性能。

**2）提高系统资源利用率**  线程池可以通过配置 `最大线程数` 来限制**并发线程**数量，防止系统资源（例如内存和 CPU）被过多的线程耗尽，从而避免资源竞争和过载。

**3）提高响应性** 正式运行阶段，处理客户端请求时，线程池中的线程可以立即处理它们，而**不需要等待新线程的创建的动态分配**；线程池中的**线程**在完成一个任务后可以放回池中，被**复用**

**`核心参数`**

1. **任务队列大小**：根据每个任务的处理时间和系统资源进行调整，设置为10000，以便监控系统性能。
  
2. **线程池数量**：我设置了4
   - **CPU核心数**：通常线程池的线程数应与CPU核心数相同或稍多。对于CPU密集型任务，建议与CPU核心数相同，以避免线程竞争；对于I/O密集型任务，可以适当增加线程数量，以减少I/O等待时间。
   - **系统资源**：需考虑线程池对内存和CPU的需求，避免过多线程导致内存占用和CPU切换开销，或过少线程导致任务排队。选择线程池数量时应综合考虑这些因素，并根据实际情况优化。

## 7.线程池|线程池怎么保证线程安全

- 使用了互斥锁，通过对共享资源的加锁和解锁来保证并发访问的安全
- 使用信号量，可以用于实现多个线程的同步和互斥
- 还可以加读写锁，条件变量和原子操作来保证线程安全

## 8.有限状态机 (finite state machine)

有限状态机是一种计算模型，它由一组状态以及在这些状态之间的转移组成。在任何给定时间，有限状态机都有一个当前状态，并且基于输入和当前状态，它可以转移到另一个状态或保持在当前状态。HTTP协议的格式和结构之所以适合使用有限状态机进行解析。<a href="###HTTP | HTTP报文">HTTP报文</a>

1. **初始状态（START）**：状态机开始等待接收HTTP请求报文。
2. **请求行状态（REQUEST_LINE）**：当状态机接收到数据时，它首先尝试解析请求行。请求行包含请求方法（如GET、POST等）、URI（统一资源标识符，它指定了请求的资源位置和路径）、以及HTTP协议的版本号。状态机将分析这些组成部分，确保它们符合HTTP协议的规范。
3. **头部状态（HEADERS）**：解析完请求行后，状态机进入头部状态，开始解析请求头。请求头由多个键值对组成，每对之间用CRLF分隔。常见的请求头字段包括Host、User-Agent、Accept等，它们提供了请求的附加信息。状态机将逐行读取并解析这些头部字段。
4. **空行状态**：在请求头解析完毕后，状态机检测到一个空行（两个连续的CRLF），这表示请求头已经结束，请求体（如果有的话）即将开始。
5. **主体状态（BODY）**：对于需要请求体的请求方法（如POST、PUT），状态机进入主体状态并开始解析请求体。请求体可能包含表单数据、JSON对象或其他类型的数据。状态机将根据请求头中的Content-Type字段来确定如何解析这些数据。
6. **结束状态（END）**：一旦请求体被完全解析，或者对于没有请求体的请求（如GET请求），状态机将进入结束状态。在这个阶段，状态机将完成对整个HTTP请求报文的解析，并准备生成相应的响应。
7. **错误状态（ERROR）**：如果在解析请求行、请求头或请求体的过程中遇到任何不符合HTTP协议规范的错误，状态机将进入错误状态。在错误状态下，状态机会记录错误信息，并准备发送一个错误响应给客户端。
8. **处理完成（REQUEST_COMPLETED）**：在结束状态之后，状态机将准备并发送响应给客户端，并返回初始状态（START），等待接收下一个HTTP请求。

整个过程确保了HTTP请求的各个组成部分被逐步解析，并且在每个阶段都有机会处理错误并重新开始。

## 8.有限状态机|主、从状态机调用关系与状态转移过程

**从状态机负责读取报文的一行，主状态机负责对该行数据进行解析**，主状态机内部调用从状态机，从状态机驱动主状态机。

### 主状态机

三种状态，标识解析位置。

- CHECK_STATE_REQUESTLINE，解析请求行
- CHECK_STATE_HEADER，解析请求头
- CHECK_STATE_CONTENT，解析消息体，仅用于解析POST请求

### 从状态机

三种状态，标识解析一行的读取状态。

- LINE_OK，完整读取一行
- LINE_BAD，报文语法有误
- LINE_OPEN，读取的行不完整

![状态机](./typora_photo/Webserver/状态机.jpg)

### 从状态机逻辑

在HTTP报文中，每一行的数据由\r\n作为结束字符，空行则是仅仅是字符\r\n。因此，可以通过查找\r\n将报文拆解成单独的行进行解析，项目中便是利用了这一点。

从状态机负责读取buffer中的数据，将每行数据末尾的\r\n置为\0\0，并更新从状态机在buffer中读取的位置m_checked_idx，以此来驱动主状态机解析。

- 从状态机从m_read_buf中逐字节读取，判断当前字节是否为\r

- - 接下来的字符是\n，将\r\n修改成\0\0，将m_checked_idx指向下一行的开头，则返回LINE_OK
  - 接下来达到了buffer末尾，表示buffer还需要继续接收，返回LINE_OPEN
  - 否则，表示语法错误，返回LINE_BAD

- 当前字节不是\r，判断是否是\n（**一般是上次读取到\r就到了buffer末尾，没有接收完整，再次接收时会出现这种情况**）

- - 如果前一个字符是\r，则将\r\n修改成\0\0，将m_checked_idx指向下一行的开头，则返回LINE_OK

- 当前字节既不是\r，也不是\n

- - 表示接收不完整，需要继续接收，返回LINE_OPEN

### 主状态机逻辑

主状态机初始状态是CHECK_STATE_REQUESTLINE，通过调用从状态机来驱动主状态机，在主状态机进行解析前，从状态机已经将每一行的末尾\r\n符号改为\0\0，以便于主状态机直接取出对应字符串进行处理。

- ==CHECK_STATE_REQUESTLINE==
  - 主状态机的初始状态，调用parse_request_line函数解析请求行
  - 解析函数从m_read_buf中解析HTTP请求行，获得请求方法、目标URL及HTTP版本号
  - 解析完成后主状态机的状态变为CHECK_STATE_HEADER


解析完请求行后，主状态机继续分析请求头。在报文中，==请求头和空行的处理使用的同一个函数，这里通过判断当前的text首位是不是\0字符==，若是，则表示当前处理的是空行，若不是，则表示当前处理的是请求头。

- ==CHECK_STATE_HEADER==
  - 调用parse_headers函数解析请求头部信息

  - 判断是空行还是请求头，若是空行，进而判断content-length是否为0，如果不是0，表明是POST请求，则状态转移到CHECK_STATE_CONTENT，否则说明是GET请求，则报文解析结束。

  - 若解析的是请求头部字段，则主要分析connection字段，content-length字段，其他字段可以直接跳过，各位也可以根据需求继续分析。

  - connection字段判断是keep-alive还是close，决定是长连接还是短连接

  - content-length字段，这里用于读取post请求的消息体长度

GET和POST请求报文的区别之一是有无消息体部分，GET请求没有消息体，当解析完空行之后，便完成了报文的解析。

但后续的登录和注册功能，为了避免将用户名和密码直接暴露在URL中，我们在项目中改用了POST请求，将用户名和密码添加在报文中作为消息体进行了封装。
为此，我们需要在解析报文的部分添加解析消息体的模块。

```cpp
while((m_check_state==CHECK_STATE_CONTENT && line_status==LINE_OK)||((line_status=parse_line())==LINE_OK))
```

在GET请求报文中，每一行都是\r\n作为结束，所以对报文进行拆解时，仅用从状态机的状态line_status=parse_line())==LINE_OK语句即可。

但在POST请求报文中，消息体的末尾没有任何字符，所以不能使用从状态机的状态，这里转而使用主状态机的状态作为循环入口条件。

- ==CHECK_STATE_CONTENT==

- - 仅用于解析POST请求，调用parse_content函数解析消息体
  - 用于保存post请求消息体，为后面的登录和注册做准备

## 9.**`epoll`** | 为什么使用epoll

### `select`：适用于少量文件描述符的场景，兼容性强（几乎所有系统都支持），但性能和扩展性有限。

- 使用固定长度的 `bitsmap` 来表示文件描述符集合。
- **文件描述符限制**：支持的文件描述符个数有限，在 Linux 中默认最大值为 1024（可以手动修改该限制），扩展性差。
- **触发方式**：采用**水平触发**（Level-triggered）。如果某个文件描述符就绪，且未被处理，则每次 `select` 调用都会重复通知该文件描述符。
- **性能问题**：通过线性结构存储和轮询遍历，时间复杂度 **O(n)**。。需要在用户态和内核态之间复制文件描述符集合，开销较大。属于同步通知机制。

### `poll`：突破了文件描述符数量的限制

- **动态数组**存储文件描述符集合，从而**突破了文件描述符个数的限制**。
- **触发方式**：同样为**水平触发**。当一个文件描述符就绪但未处理，`poll` 调用后仍会重复通知。
- **性能问题**：通过线性结构存储和轮询遍历，时间复杂度 **O(n)**。。需要在用户态和内核态之间复制文件描述符集合，开销较大。属于同步通知机制。

### `epoll`：最适合大规模、高并发的网络服务器开发

- `epoll` 是基于**事件驱动**机制（Event-driven）进行的异步通知。
- **性能提升**：`epoll` 在内核中维护了一个**就绪事件链表**。当某个 `socket` 有事件发生时，内核通过**回调函数**将其加入到就绪事件链表中，用户只需要调用 `epoll_wait()` 来获取已经准备好的事件，无需遍历整个文件描述符集合，效率大大提高。
- **数据结构管理**：使用内核中的 **红黑树** 数据结构来管理 **待检测的 `socket`** ，增删查的时间复杂度为 **O(logn)**。
- **文件描述符无数量限制**：相较于 `select`，`epoll` 无文件描述符数量限制，能够处理大量的文件描述符。并且，`epoll_ctl()` 只需注册一次 `socket`，每次调用时无需重新传入整个文件描述符集合，减少了用户态与内核态之间的多次拷贝。
- **触发方式**：支持**水平触发**和**边缘触发**（Edge-triggered）。尤其在**边缘触发**模式下，只有当 `socket` 状态发生变化时才会通知用户，避免了不必要的重复通知，进一步提升了处理效率。


### 总结对比

| 特性               | `select`                             | `poll`                               | `epoll`                                   |
| ------------------ | ------------------------------------ | ------------------------------------ | ----------------------------------------- |
| **数据结构**       | 固定大小 `bitsmap`                   | 动态数组                             | 红黑树（管理 `socket`）+ 链表（就绪事件） |
| **文件描述符限制** | 默认 1024（可更改）                  | 无限制                               | 无限制                                    |
| **触发方式**       | 水平触发                             | 水平触发                             | 支持水平触发和边缘触发                    |
| **时间复杂度**     | O(n)，需遍历所有描述符               | O(n)，需遍历所有描述符               | O(logn) 增删改 + O(1) 处理就绪事件        |
| **效率**           | 随着文件描述符增加而下降             | 随着文件描述符增加而下降             | 高效，特别是在高并发场景下                |
| **数据拷贝**       | 用户态和内核态之间每次都需要复制集合 | 用户态和内核态之间每次都需要复制集合 | 只需传入一次文件描述符，后续无需重复传递  |
| **使用场景**       | 适合少量文件描述符                   | 适合中等数量文件描述符               | 适合大规模并发和高频事件处理              |


  > `epoll_create` 创建一个` epoll`对象 `epfd`，
  > 通过 `epoll_ctl` 将需要监视的 socket 添加到`epfd`中
  > 调用 `epoll_wait` 等待发生事件`fd`资源
  >  ![img](./typora_photo/Webserver/epoll.png)
```cpp
int s = socket(AF_INET, SOCK_STREAM, 0);
bind(s, ...);
listen(s, ...)

int epfd = epoll_create(...);
epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中

while(1) {
    int n = epoll_wait(...);
    for(接收到数据的socket){
        //处理
    }
}
```

## 9.**`epoll`** | epoll如何减少拷贝和开销：

- **一次性注册**：`epoll_ctl()` 通过注册文件描述符到内核态，可以避免每次调用时都传递整个文件描述符集合。这与 `select` 和 `poll` 需要每次调用时从用户态传递文件描述符集合有显著区别。
- **就绪事件链表**：内核中使用事件驱动机制（通过回调函数）将就绪的事件添加到就绪链表中，调用 `epoll_wait()` 时只返回已准备好的文件描述符，避免了扫描整个文件描述符集合。
- **减少重复拷贝**：`epoll` 只在事件注册时拷贝文件描述符集合，之后的 `epoll_wait()` 只传递已发生事件的文件描述符，极大减少了用户态和内核态之间的拷贝开销。

## 9.**`epoll`** | epoll中可以无限承载socket的连接吗？创建socket时的返回值是什么

- epoll本身没有连接数的限制 但是内存是有限的，**1G的内存上能监听约10w个端口**
- 如果Socket创建成功，返回的是一个整数的文件描述符，用于后续的Socket操作。如果创建失败，则会返回`-1`，并且可以使用errno变量来获取具体的错误信息

## 9.**`epoll`** | 边缘触发ET和水平触发LT

epoll 支持两种事件触发模式，分别是**边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）**。

**LT（muduo采用）**：内核数据没读完，就会一直上报数据。**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束。**

- muduo为什么使用LT模式：不会丢失数据；照顾多个连接的公平性，低延迟处理；跨平台使用，ET一些系统不能使用

**ET**：内核数据只上报一次。**服务器端只会从 epoll_wait 中苏醒一次**。

## 9.**`epoll`** | EPOLLONESHOT | 解决竞态条件和潜在的数据不一致

LT只要存在事件就会不断的触发，ET只在从非触发到触发两个状态转换的时候才触发。

**存在问题：**多线程处理中，一个Socket事件到来，数据开始解析，这时候这个Socket又来一个相同的事件，在前一个解析未完成情况下，程序会自动调用另外一个线程或进程处理新的事件，造成了**不同线程和进程处理同一个socket事件**。

**EPOLLONESHOT解决：**将 socket 文件描述符和 `EPOLLONESHOT` 标志一起注册到 epoll 实例中。这样，当事件发生时，它只会被触发一次。在当前线程完成事件处理后，需要再次使用 `epoll_ctl` 与 `EPOLL_CTL_MOD` 命令来重新注册该 socket 文件描述符，以便它可以对新的事件做出响应。从而保证不会跨越多个线程。

## `fd`在系统中有限制吗？

**有限制的**。

1. 单个进程中默认是`1024`

   ```shell
   ulimit -n	# 查看当前进程的fd数量限制
   ulimit -n num	# 修改当前进程的fd数量限制
   ```

   进程中可以用系统函数修改

   ```cpp
   #include <sys/resource.h>
   struct rlimit {
       rlim_t rlim_cur;	// soft limit
       rlim_t rlim_max;	// hard limit
   };
   // get resource limit
   int getrlimit(int resource, struct rlimit *rlimit);
   // set resource limit
   int setrlimit(int resource, const struct rlimit *rlimit);
   ```

2. 操作系统对文件描述符也有限制，进程分配的文件描述符数量不能超过操作系统的限制，可以通过修改内核参数来调整阈值。文件描述符总是有数量的，取决于系统的配置和硬件资源。

   ```shell
   sysctl fs.file-max = 655360
   ```

## 一个服务端进程最多和多少个客户端进行连接？和fd的数量有关系吗？

文件描述符的数量与同时连接的客户端数量有关，因为每个客户端连接都需要⼀个文件描述符。但是fd并不是唯一影响同时连接客户端数量的因素。

**其他因素**  

- 内存：每一个连接都会消耗一定的内存，内存大小会限制同时连接的客户端数量
- 网络宽带：每个联机的数据传输需要网络宽带
- 处理器性能

## 10.WebBench访问请求原理

- 父进程fork若干个子进程，每个子进程在用户要求或默认时间内对wb循环发起实际访问请求。

- 父子进程通过管道进行通信，子进程通过 **管道写端** 向父进程传递若干次请求访问完毕后记录到的总信息

- **父进程** 通过 **管道读取** 子进程发来的相关信息

- 子进程在时间后结束，父进程在所有子进程退出后统计并给用户显示最后结果。退出

  <img src="./typora_photo/Webserver/image-20240725233235228.png" alt="image-20240725233235228" style="zoom:50%;" />

## 负载均衡

分配网络或者应用的流量到==多个服务器==上，优化资源利用，提高响应速度和增加系统可靠性。

Nginx 默认实现了 **轮询** 和 **最小连接数** 两种负载均衡算法，并支持通过配置实现 **加权轮询** 和 **IP 哈希**。

**见的负载均衡算法包括以下几种：**

是的，常见的负载均衡算法包括以下几种：

1. **轮询（Round Robin）**：
  
   - **描述**：将请求按顺序轮流分配到每个服务器上。每个服务器在处理完一个请求后，下一个请求就会分配到下一个服务器。
   - **优点**：简单易实现，适用于服务器性能相近的场景。**缺点**：不考虑服务器的实际负载或性能差异。

   ```nginx
   upstream backend {
       server backend1.example.com;
       server backend2.example.com;
       server backend3.example.com;
   }
   ```
   
2. **随机（Random）**==nginx不支持==：
  
   - **描述**：随机选择一台服务器来处理每个请求。这种方法简单且具有一定的负载均衡效果。
   - **优点**：实现简单，负载均衡效果依赖于随机性的良好分布。**缺点**：可能会导致某些服务器过载，而其他服务器闲置。

3. **最小连接数（Least Connections）**：
  
   - **描述**：将请求分配给当前连接数最少的服务器。这有助于确保负载均衡时各服务器处理的请求数量相对均衡。
   - **优点**：更能反映服务器当前的负载状态。**缺点**：需要实时跟踪每个服务器的连接数，可能会增加开销。

   ```nginx
   upstream backend {
       least_conn;
       server backend1.example.com;
       server backend2.example.com;
       server backend3.example.com;
   }
   
4. **加权轮询（Weighted Round Robin）**：
   - **描述**：与轮询类似，但每台服务器被赋予一个权重，权重高的服务器会处理更多的请求。
   - **优点**：可以根据服务器的实际能力调整负载分配。**缺点**：需要配置权重参数，可能不适用于服务器能力变化频繁的场景。
   
   ```nginx
   upstream backend {
       server backend1.example.com weight=3;
       server backend2.example.com weight=1;
       server backend3.example.com weight=2;
   }
   ```
   
5. **加权最小连接数（Weighted Least Connections）** ==nginx不支持==：
  
   - **描述**：在最小连接数的基础上考虑服务器的权重，权重高的服务器即使连接数少，也可能会处理更多的请求。
   - **优点**：结合了最小连接数和加权策略的优点，适用于能力差异大的服务器集群。**缺点**：配置复杂，需要合理设定权重。

6. **IP 哈希（IP Hash）**：
  
   - **描述**：根据客户端的 IP 地址计算哈希值，将请求分配到特定的服务器上。相同的 IP 地址会被分配到同一台服务器，从而实现会话保持。
   - **优点**：实现会话保持，确保同一客户端的请求始终由同一台服务器处理。**缺点**：如果服务器数量变化或 IP 地址分布不均，可能会导致负载不均。
   
   ```nginx
   upstream backend {
       ip_hash;
       server backend1.example.com;
       server backend2.example.com;
       server backend3.example.com;
   }
   ```

## 在服务端接受accept()之后，socket就是一直可读吗？就是调用read()函数一直可以读吗？会阻塞吗



## Qt信号槽机制的优势和不足

优点：类型安全，松散耦合。缺点：同回调函数相比，运行速度较慢。

---

## 问题01|使用优先级队列优化定时器

**描述：**优先级队列来优化定时器时候，初步构思是使用标准模板库（STL）中的`priority_queue`实现。调整定时器adjust_timer操作的时候，相应需要修改保存的定时器指针内部的expire_time的值。但是这并**不会触发自动排序。**

**原理**：`priority_queue`不提供直接修改元素值的接口，后面考虑这是因为**`priority_queue`是基于堆实现的**，允许访问或移除队首元素元素，同时排序依赖于元素的值，而直接修改元素值不会触发重新排序。

**解决方法：**

1. **使用 `vector` 实现小顶堆**：构建一个自定义的小顶堆，通过 `vector` 来存储定时器。定时器以小顶堆的形式存储，确保堆顶始终是过期时间最小的定时器。

2. **使用 `unordered_map`**：维护一个哈希表，将定时器与其在 `vector` 中的索引对应起来，以便快速查找。
3. **调整定时器**：
   - 通过哈希表找到定时器在 `vector` 中的位置。
   - 修改定时器的过期时间。
   - 将该元素移动到合适的位置，使用“上浮”或“下沉”操作来保持小顶堆的性质。当调整定时器的过期时间时，会调用 `bubbleUp` 或 `bubbleDown` 方法。这些方法通过比较节点的过期时间，维护小顶堆的性质

## 问题02|使用`pthread_create`创建线程

**描述：**使用 **pthread_create** 创建线程时，**如果线程函数是类的一个非静态成员函数，会遇到编译错误**

**原理**：**`pthread_create`**函数要求传入的线程函数是一个普通函数，其函数指针类型为`void*(*)(void*)`。这意味着线程函数只能接受一个`void*`类型的参数，而不包括任何额外的参数（如`this`指针）。

- `pthread_create`接受参数包含：指向新线程的标识符指针、线程属性的指针、线程函数的地址和传递给线程函数的参数。

- **线程函数的要求：`pthread_create`要求传入的线程函数是一个普通函数。该函数指针必须接受一个`void*`类型的参数，且该函数返回类型必须是`void*`。**

- **非静态成员函数**的问题：

  **隐含的`this`指针**：非静态成员函数与普通函数不同，因为它们包含一个隐含的`this`指针，指向调用该函数的对象实例。

  **函数指针不兼容**：由于非静态成员函数需要一个额外的`this`指针参数，因此无法直接转换为`void*(*)(void*)`类型的函数指针。编译器会期望得到一个`this`指针，这导致了与`pthread_create`要求的函数指针类型不匹配，从而导致编译错误。

**解决方法**：

1. 声明线程函数为**静态成员函数**：静态成员函数不隐含`this`指针

```c++
int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg);
```

```cpp
// 线程函数，必须是静态的，因为它将被pthread_create调用
static void* threadFunction(void* arg) {
    // 这里可以执行一些线程任务
    std::cout << "Thread with ID " << pthread_self() << " is running." << std::endl;
    return nullptr; // 线程函数应返回void*
}

int main() {
    pthread_t thread_id;
    // 创建线程
    if (pthread_create(&thread_id, NULL, threadFunction, NULL) != 0) {
        std::cerr << "Error creating thread" << std::endl;
        return 1;
    }
    // 等待线程结束
    pthread_join(thread_id, NULL);
    std::cout << "Thread with ID " << thread_id << " finished." << std::endl;
    return 0;
}
```

2. 使用普通函数
3. 使用lambda表达式：捕获对象指针并在其中调用非静态成员函数。

## 问题03|解决MySQL `mysql_real_connect` 发生段错误 (核心已转储)

**描述：**在使用Nginx进行负载均衡，并通过Redis集群服务器进行通信的方案中，我们遇到了`mysql_real_connect`方法引发的段错误。Redis中使用独立线程接收订阅通道消息

**Nginx负载均衡 + Redis集群服务器通信**

   1. **Nginx负载均衡**：

      - Nginx作为反向代理服务器，负责将客户端请求分发到不同的后端服务器，以实现负载均衡和高可用性。
      - 通过配置Nginx，可以将请求分发到多个应用服务器，提升系统的处理能力。

   2. **Redis集群服务器通信**：

      - Redis作为高性能的内存数据库，用于在集群服务器之间进行通信和数据共享。

      - 通过Redis的发布/订阅机制，实现消息的广播和处理。

**解决方法**

在调用`mysql_real_connect`时，程序发生段错误并生成核心转储。这通常是由于指针或内存管理问题引起的。

1. **确保`conn_`指针已正确初始化**：
   - 在调用`mysql_real_connect`之前，必须确保`conn_`已经通过`mysql_init`正确初始化。
2. **检查字符串参数的有效性**：
   - 确保传递给`mysql_real_connect`的字符串参数（例如`server.c_str()`, `user.c_str()`, `password.c_str()`, `dbname.c_str()`）是有效的。

  3. **增加错误检查和日志**：
     - 在调用`mysql_real_connect`之前和之后增加详细的日志输出，以便更好地理解问题发生的位置。


**试图访问`reply->element[2]`和`reply->element[2]->str`，但是`reply`可能为`nullptr`，或者`reply->element`数组没有足够的元素**

1.    增加了对`redisReply`对象及其成员的检查：

```cpp
// 在独立线程中接受订阅通道的消息
void Redis::observer_channel_message()
{
    redisReply *reply = nullptr;
    while (REDIS_OK == redisGetReply(this->subcribeContext_, (void **)&reply))
    {
        if (reply != nullptr)
        {
            if (reply->type == REDIS_REPLY_ARRAY && reply->elements >= 3)
            {
                if (reply->element[2] != nullptr && reply->element[2]->str != nullptr)
                {
                    // 给业务层上报通道发生的消息
                    notifyMessageHandler_(atoi(reply->element[1]->str), reply->element[2]->str);
                }
            }
            freeReplyObject(reply);
        }
    }
    cerr << ">>>>>>>>>>>>> observer_channel_message quit <<<<<<<<<<<<<" << endl;
}
```

   > Redis回复的类型包括：
   >
   > 1. **`REDIS_REPLY_STRING`**：回复是一个字符串。
   > 2. **`REDIS_REPLY_INTEGER`**：回复是一个整数。
   > 3. **`REDIS_REPLY_ARRAY`**：回复是一个数组，通常用于订阅消息。
   > 4. **`REDIS_REPLY_NIL`**：回复为空。
   > 5. **`REDIS_REPLY_STATUS`**：回复是一个状态字符串（如命令执行成功的信息）。
   > 6. **`REDIS_REPLY_ERROR`**：回复是一个错误消息。

   **在处理订阅消息时，Redis的回复通常是一个包含三元素的数组：**

      1. 消息类型（如 "message"）
      2. 频道名称
      3. 消息内容