# 操作系统

## 存储系统 | 内存分页 缺页中断

缺页终端就是当软件试图访问一个已经映射在虚拟地址空间中，但并未加载到物理内存中的分页时，由中央处理器的内存管理单元所发出的中断。

- **软性页缺失**：
- **硬性页缺失：**
- **无效页缺失：**

## 什么是中断和异常  

中断和异常都会导致处理器暂停当前正在执行的任务，并转向执行一个特定的处理程序（中断处理程序&异常处理程序），然后在处理完这些特殊情况后，处理器会返回到被打断的任务继续执行。

### 中断**：**由计算机系统的外部事件触发的，通常和硬件设备相关。

- 目的：及时响应重要事件而暂时中断正常的程序执行

- 典型中断：时钟中断、IO设备中断（鼠标键盘）、硬件错误中断。操作系统通常会为每个类型中断分配一个中断处理程序。

- 中断会打断其他进程运行，并且中断处理程序响应中断时，可能还会**临时关闭中断**。也就是说，当前中断程序未执行完，系统中其他中断无法被响应，所以中**断可能发生丢失**。**要求中断程序短且快。**

- Linux解决：**中断处理程序执行过长和中断丢失。将中断分为上下半部**
  - 上半部：直接处理硬件请求，即硬中断。一般会关闭中断请求，主要负责耗时短工作，快速执行；
  - 下半部：内核触发，即软中断。负责上班未完成工作，以内核线程方式运行，延迟执行。


### 异常：由计算机系统的内部事件触发的，通常和正在执行的程序或指令有关

- 程序的非法操作、地址越位、运算符溢出等错误引起的事件
- 异常不能被屏蔽。出现异常，计算机系统暂停正常执行，转到异常处理程序处理异常。

## 进程和线程|进程和线程的区别  

- **调度**：线程是程序执⾏的基本单位；进程是拥有资源的基本单位。

- **并发性**：进程内部的多个线程并发； 不同进程之间切换实现并发，各⾃占有CPU实现并⾏

- **拥有资源**：线程不拥有系统资源，但单进程的多个线程可以共享属于进程的资源；进程是拥有资源的独⽴单位。

- **系统开销**：线程切换时只需保存和设置少量寄存器内容、程序计数器和栈指针，因此开销很小；进程需要切换虚拟地址空间，切换内核栈和硬件上下文等，开销很大

## 进程和线程|进程间通信

（进程间通信 IPC，Inter-Process Communication）

- **管道：**管道是一种半双工的通信方式，数据只能单向流动
  - 无名管道（内存文件）：只能在具有亲缘关系的进程之间使用，通常为父子进程
  - 有名管道（FIFO文件）：可以在不相关的进程之间交换数据
- **共享内存：**共享内存就是映射一段能被其他进程访问的内存，该段内存由一个进程创建，但是多个进程可以访问。共享内存是**最快的的IPC方式**，往往和信号量配合使用来实现进程间的同步和通信
- **消息队列：**是有消息的链表，存放在内核中并由消息队列识别符标识。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓存区大小受限等缺点。
- **信号：**用于通知进程某个事件已经发生：比如`ctrl+c`就是一个信号量
- **信号量：**是一个计数器，用来控制多个进程对共享资源的访问
- **套接字：**适用于不同机器之间进程通信，在本地也可以作为两个进程的通信方式

|      通信机制      |                        描述                        | 优点                                         | 缺点                                                       |
| :----------------: | :------------------------------------------------: | :------------------------------------------- | :--------------------------------------------------------- |
|  无名管道 (Pipe)   | 单向通信，数据通过管道从一个进程传递到另一个进程。 | 简单易用，适用于父子进程间的通信。           | 只能用于有亲缘关系的进程间通信，数据传输速度较慢。         |
|  有命管道 (FIFO)   |      类似于管道，但可以用于任意进程间的通信。      | 支持无亲缘关系的进程间通信，使用简单。       | 需要创建和管理命名管道文件，数据传输速度较慢。             |
|      共享内存      |       多个进程共享一块内存区，实现高速通信。       | 通信速度快，数据存储在共享内存中，效率高。   | 需要同步机制来防止数据竞争，管理复杂。                     |
|      消息队列      |  进程通过发送和接收消息来通信，消息存储在内核中。  | 支持随机读取消息，有优先级机制，灵活性高。   | 消息长度受限，内核维护消息队列，占用系统资源。             |
|   信号 (Signal)    |            用于通知进程某个事件的发生。            | 简单高效，适用于异步事件通知。               | 信号量有限，信息量少，适用于简单通知，不适合大数据量传输。 |
| 信号量 (Semaphore) |     主要用于进程间的同步，可以实现互斥和同步。     | 提供了严格的同步机制，控制进程间的访问顺序。 | 仅用于同步，不能传递复杂信息，管理和使用较为复杂。         |
|  套接字 (Socket)   |        支持网络通信，可以在不同机器间通信。        | 功能强大，支持跨网络通信，适用于分布式系统。 | 通信开销较大，设置和使用较为复杂。                         |

## 进程和线程|线程间同步

线程同步机制是指在多线程编程中，为了防止线程之间可能会产出的竞态条件，保证互不⼲扰，而采用的⼀种机制。

常见的线程同步机制有以下几种：  

1. **互斥锁（Mutex）**：互斥锁是一种基本的同步机制，用于防止多个线程同时访问某个共享资源。当一个线程获取了互斥锁，其他线程必须等待直到该锁被释放。
2. **读写锁（Read-Write Lock）**：读写锁允许多个线程同时读取数据，但写入数据时需要独占访问。这可以提高性能，因为读操作通常比写操作频繁。
3. **信号量（Semaphore）**：信号量是一种计数器，用来表示可用资源的数量。**线程在访问资源前需要先获取信号量，访问完成后释放信号量。**对应的变量是一个整型（sem）变量。两个原子操作的系统调用函数来控制信号量的，分别是：
   - P 操作：将 sem 减 1，相减后，如果 sem < 0，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；
   - V 操作：将 sem 加 1，相加后，如果 sem <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；如果sem > 0，则表明当前没有阻塞中的进程；
4. **条件变量（Condition Variable）**：条件变量用于线程间的协调，允许一个或多个线程在某些条件成立之前挂起执行，并在条件满足时被唤醒。

## 进程和线程|条件变量怎么用

条件变量和锁是紧密相关的。

锁的使用场景：一个事同时只有一个人做，我抢到锁就我先进去操作，操作完毕再给下一个做

条件变量场景：

1. 首先，这件事情还是只能由一个人做，所以还是要用到**锁**，但线程抢到锁之后，发现还要**等待一些条件满足**才能做

2. 这时如果抢到的锁的线程一直循环检查这个条件，消耗高，而且每次检查完为了**不让CPU一直空跑**，需要sleep一下。

   sleep少，消耗高，sleep长，则有延迟，无法及时发现条件满足。抢到锁后的一直检查别的线程就无法拿到锁了

3. **引入条件变量**，抢到所得线程发现条件未满足时，释放锁，使用`pthread_cond_wait()`**挂起**自己。

   这时别的线程可以获取锁进来，发现条件不满足同样挂起；

   直到条件满足，由其他地方调用`pthread_cond_broadcast()`**来唤醒全部挂掉的线程**，或者调用`pthread_cond_signal`唤醒指定线程。

## 进程和线程|消费者生产者模型

一种多线程编程中的经典同步问题。其主要目的是在共享资源（通常是缓冲区）上协调多个生产者线程和消费者线程的操作。

- **生产者（Producer）**：生产者线程的任务是生成数据并将其放入共享缓冲区。当缓冲区满时，生产者线程需要等待直到缓冲区有空间。

- **消费者（Consumer）**：消费者线程的任务是从共享缓冲区中取出数据进行处理。当缓冲区为空时，消费者线程需要等待直到缓冲区中有数据。

```cpp
#include <pthread.h>
#include <iostream>
#include <queue>
#include <unistd.h>

using namespace std;

// 定义一个模板类，用于实现阻塞队列
template<typename T>
class BlockQueue {
private:
    // 检查队列是否已满
    bool isFull() {
        return que.size() == _capacity;
    }

    // 检查队列是否为空
    bool isEmpty() {
        return que.empty();
    }

public:
    // 构造函数，初始化队列容量及互斥锁和条件变量
    BlockQueue(int cap = 5) :_capacity(cap) {
        pthread_mutex_init(&_mutex, NULL);  // 初始化互斥锁
        pthread_cond_init(&_full, NULL);    // 初始化条件变量，表示队列满
        pthread_cond_init(&_empty, NULL);   // 初始化条件变量，表示队列空
    }
    
    // 析构函数，销毁互斥锁和条件变量
    ~BlockQueue() {
        pthread_mutex_destroy(&_mutex);     // 销毁互斥锁
        pthread_cond_destroy(&_full);       // 销毁条件变量 _full
        pthread_cond_destroy(&_empty);      // 销毁条件变量 _empty
    }

public:
    // 生产者调用此方法向队列中添加元素
    void push(const T& data) {
        pthread_mutex_lock(&_mutex);        // 加锁，进入临界区
        while (isFull()) {                  // 如果队列已满，则生产者等待
            pthread_cond_wait(&_full, &_mutex);
        }
        que.push(data);                     // 添加元素到队列
        pthread_cond_signal(&_empty);       // 通知消费者队列非空
        pthread_mutex_unlock(&_mutex);      // 解锁，离开临界区
    }
    
    // 消费者调用此方法从队列中取出元素
    void pop(T& data) {
        pthread_mutex_lock(&_mutex);        // 加锁，进入临界区
        while (isEmpty()) {                 // 如果队列为空，则消费者等待
            pthread_cond_wait(&_empty, &_mutex);
        }
        data = que.front();                 // 取出队列头部的元素
        que.pop();                          // 弹出队列头部的元素
        pthread_cond_signal(&_full);        // 通知生产者队列非满
        pthread_mutex_unlock(&_mutex);      // 解锁，离开临界区
    }

private:
    queue<T> que;                           // 队列容器
    int _capacity;                          // 队列的容量
    pthread_mutex_t _mutex;                 // 互斥锁，用于保护临界区
    pthread_cond_t _full;                   // 条件变量，表示队列满
    pthread_cond_t _empty;                  // 条件变量，表示队列空
};

```

## 存储系统|虚拟内存

虚拟地址空间构成虚拟内存，它使得应用程序认为自己拥有连续的可用内存空间，但实际上是被分隔的多个物理内存页、以及部分暂时存储在磁盘上的交换分区所构成的。

- **程序局部性原理**（Principle of Locality）：程序在运行过程中对数据和指令的访问表现出一定的规律性，即**时间局部性**和**空间局部性**。利用局部性原理，可以优化缓存性能，提高程序运行效率。

进程在运行时，不会一下子就要访问所有内存，进程对于内存的访问表现出明显的倾向性。在某一段时间内，进程真正需要的的资源只是很少一部分。

**进程更倾向访问最近访问过的数据（`时间局部性`），以及热点数据附近的数据（`空间局部性`）。**

1. 虚拟内存的引入，解决了内存利用效率问题。每个进程都有属于自己的虚拟内存地址，进程间的虚拟内存地址相互隔离，互不打扰；
2. 每个进程都认为自己独占所有的内存空间，所有内存资源都属于自己，但其实任何⼀个虚拟内存⾥存储的数据，**本质上还是保存在物理内存**里的，只不过内核帮我们做了**虚拟内存到物理内存这⼀层的映射**，将不同进程的虚拟地址和不同内存的物理地址映射起来；

## 存储系统|malloc底层是怎么分配内存的

malloc 并不是系统调用，而是C库里的函数，用来动态分配内存。

malloc() 分配的是**虚拟内存**。如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。

malloc 向操作系统申请堆内存方式有两种：

- 通过 **`brk()`** 系统调用从堆分配内存：将「**堆顶**」指针向高地址移动，获得新的内存空间

- 通过 **`mmap()`** 系统调用在文件映射区域分配内存：调用中「**私有匿名映射**」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存

- malloc() 源码里默认定义了一个阈值：如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存

  ![image-20240815161848786](.\typora_photo\操作系统\image-20240815161848786.png)

## 存储系统|malloc(1)会分配多大的虚拟内存

malloc在分配内存的时候，**会预分配更大的空间作为内存池**。具体预分配多大的空间，和malloc使用的内存管理器有关。

**默认**的内存管理器对于malloc(1)，16000+KB 17字节左右

## 存储系统|为什么不全部使用 `brk` 或 `mmap` 来分配内存

完全使用 `mmap` 来分配内存有以下几个缺点：

- **上下文切换的开销**：每次调用 `mmap` 都需要从用户态切换到内核态，这会导致性能损失。频繁的上下文切换会增加系统调用的开销，降低程序的运行效率。
- **缺页中断增加**：使用 `mmap` 分配的内存往往是“懒惰”分配的，即分配的内存最初并没有映射到物理内存上。当你首次访问这块内存时，会触发缺页中断，由操作系统将虚拟内存映射到物理内存。这增加了 CPU 的消耗，尤其是在大量小块内存分配的情况下。

通过 `brk` 方法分配内存有如下问题：

- **内存碎片化**：当程序频繁地分配和释放不同大小的内存块时，堆内存可能会产生碎片。小块内存的分配和释放会导致内存碎片的产生，这些碎片可能无法被有效利用。随着时间的推移，堆内存中的碎片会增多，导致内存利用率降低，甚至可能导致内存不足。
- **无法释放**：通过 `brk` 分配的内存**只能在堆的顶部释放**。即，如果堆的顶部没有释放的空间，那么即使底部有空闲的内存，也无法通过 `brk` 收回。这意味着内存可能会被占用而无法重用，导致“内存泄漏”式的问题。

## 存储系统|`free`函数只传入⼀个内存地址，为什么能知道要释放多大的内存

**内存分配器的数据结构有关**

- **元数据：**当使用`malloc`等函数分配内存时，内存分配器通常在实际返回给用户之前的的内存块**存储了一些管理信息**，成为元数据。这其中就包含内存块的大小
- **内存分布：**在实际内存分布中，请求32字节，可能会分配一块更大的内存（例如48字节）

**当`free`被调用时候，分配器可以通过给定的用户指针向前找到这些元数据，从而知道要释放多大的内存**

- 16字节是一个常见的**元数据大小**
- 在32位系统上，指针大小通常是4字节，而在64位系统上通常是8字节。
- 为了内存访问的效率，内存块通常需要按一定的**边界对齐**（如8字节或16字节）

## 存储系统|伙伴系统

内存碎片是计算机内存管理中一个常见的问题，主要分为两种：**外部碎片**和**内部碎片**。外部碎片是指空闲内存存在于小的、分散的块中，使得即使有足够的总空闲内存，也无法满足大块内存的分配请求。内部碎片发生在分配的内存块比实际需要的内存稍大时，导致未使用的内存空间被浪费。

伙伴系统是一种减少和控制外部碎片的，用于内存分配和回收的算法。他将内存分为若**内存块**，然后尽可能以最合适的方式满足程序内存需求。

1. **内存块的大小**：伙伴系统中的内存块大小总是2的幂（例如，32字节、64字节、128字节等）

2. **伙伴的概念**：每个内存块都有一个“伙伴”块，其大小相同，地址相邻。当两个伙伴块都是空闲的时，它们可以合并成一个更大的块；相反，一个大的内存块可以被分割成两个小的伙伴块来满足更小的内存请求

3. **内存分配：**如果请求的连续内存数量是k，那么伙伴系统将选择满足**`2^n >= k的最小数字n对应的内存块`**，

   如果伙伴系统中没有对应的内存块，那么系统会将更大的分组劈开形成⼀对伙伴，然后看劈开后的分组是否合适，不合适的话就继续劈开，直到到达合适的大小为止

4. **内存释放：**当一个内存块被释放时，他会检查他的伙伴是否是空闲的。这个过程同样是递归执行，直到不能合并为止（当前伙伴繁忙或已经形成最大内存块）

##  Linux中为什么设计了内核态和用户态

处于安全性和稳定性考虑。

- **安全性** 内核态具有最高的特权级别。1.能够执行所有的CPU指令并访问所有的内存地址；2.内核态可以直接访问硬件设备；3.某些特权指令只有在内核态才能执行，例如内存管理（如设置页表）、设备控制（如I/O端口访问）、中断处理和系统状态设置（如设置时钟）。

  而**用户态**具有较低的特权级别，限制了对系统资源的直接访问。**`这虽然增加了一些开销，防止用户程序进行不安全或非法的操作，导致系统崩溃`**

- **稳定性** 如果用户态的程序出现错误或崩溃，**`只会影响该特定程序`**，而不会影响到内核或其他用户态程序。操作系统可以在用户程序出错时采取措施进行**`恢复`**，例如通过进程隔离和内存保护机制来捕获和处理异常.

- **资源管理**  内核态**`负责管理系统的硬件资源`**，如CPU、内存、硬盘和网络设备等，负责进程调度和上下文切换。用户态程序必须通过系统调用（system call）请求内核服务。

## 有什么方式进行内核态和用户态的切换

- 系统调用（System Call）
  由于某些操作（如文件操作、进程控制、内存管理等）需要访问受保护的系统资源，而用户态无法直接完成这些操作，因此需要通过系统调用切换到内核态执行。**主动发起的请求**
- 出现异常
  用户程序在执行过程中发生的**`意外情况`**（如除零错误、非法内存访问等），需要内核处理。发生异常时，CPU会自动切换到内核态，执行内核中的异常处理程序。**系统被动地进行处理**
- 外围设备中断
  外围设备（如硬盘、网络接口、键盘等）发出中断信号时，当前**`正在执行的用户态进程会被暂停`**，CPU切换到内核态处理中断。中断处理完成后，CPU可能会**`继续执行`**被暂停的用户态进程。

## epoll是同步的还是异步的

1. **从I/O层⾯来看，EPOLL⼀定是同步的**。通过 `epoll_wait` 函数来等待事件发生。当调用 `epoll_wait` 时，如果没有任何事件发生，**调用进程会被阻塞，直到有事件被触发或超时。**从这个角度来看，epoll 本身并不改变 I/O 操作的同步特性，即 I/O 操作需要等待直到完成。
2. **从消息处理层面来看，EPOLL是异步的**。允许应用程序注册感兴趣的 I/O 事件，并在发生时才进行处理，而不是持续轮询。是一种事件驱动的异步处理。内核会跟踪所有注册的文件描述符。

## 小根堆（小顶堆）定时器，如果⼀次Pop⼀个的话，高并发情况下会不会有问题  

可能会遇到一些问题，特别是当多个线程同时访问和操作堆时。

**锁竞争** 多个线程同时对小根堆进行 `pop` 操作而不加锁，可能会导致竞态条件。大量线程竞争同一个锁，会导致锁争用和上下文切换频繁，影响整体性能。

**解决方案** 

1. 考虑细粒度锁，而不是整个堆加锁；

2. 使用时间轮定时器：划分为多个槽（bucket），每个槽代表一个时间间隔，将定时任务放入相应的槽中

## 互斥和同步|`死锁`产生的条件是什么？C++怎么避免死锁

**死锁：**两个或多个并发的进程，如果每个进程持有某个资源的同时又在等待其他的进程释放资源，导致程序无法向前推进，称这组进程产生了死锁。简单地说，两个或者多个进程无限期地阻塞，互相等待的状态。

### **四个条件，同时满足**

- **互斥：**一个资源只被一个进程使用
- **不可抢占：**进程已获资源，在未使用完成钱不能被强行剥夺
- **占有并等待：**一个进程因请求资源而阻塞，对已获得资源保持不放
- **循环等待：**若干进程之间形成一种首尾相接的循环等待资源关系

### **避免死锁**

- 破坏互斥条件：修改代码使得资源可以被多个资源并行使用，**例如使用共享内存**
- 破坏不可抢占：在一些情况下，**允许系统强制剥夺进程所占有的资源**
- 破坏占用并等待：进程请求资源时候，**先释放已经请求的资源，再去请求新的资源**
- 破坏循环等待：按照一定的规则对资源进行排序，按照进程按照相同顺序请求资源。

## 互斥和同步|介绍⼀下你知道的锁

**两个基础的锁，三个特殊锁：**  

1. **互斥锁：**互斥锁是一种常见的锁类型，用于实现互斥访问共享资源。在任何时候只有一个线程可以持有互斥锁，其他线程必须等待直到锁释放。确保了同一时间只有一个线程能够访问被保护的资源；

​	**互斥锁加锁失败的线程会「线程切换」**。从用户态陷入到内核态，让内核帮我们切换线程，有**两次线程上下文切换的成本**。

`如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。`

2. **自旋锁：**通过 CPU 提供的 `CAS` 函数（*Compare And Swap*），在「用户态」完成加锁和解锁操作，**不会主动产生线程上下文切换**，所以相比互斥锁来说，会快一些，开销也小一些。**加锁失败的线程会「忙等待」**；

3. **读写锁：**允许多个线程**共同读资源**，只允许**一个线程写操作**。分为读(共享)和写(排他)两种状态；

4. **悲观锁：**认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突。工作方式：访问共享资源前，先要上锁。

5. **乐观锁：**认为多线程同时修改共享资源的概率比较低，于是不容有出现冲突。工作方式：先修改完共享资源，再验证这间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。**乐观锁全程并没有加锁，所以它也叫无锁编程**。

   **如何实现乐观锁**：

   - **版本号（Version Number）机制:**为数据库表增加⼀个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值⼀同读出，数据每更新⼀次，对此version值加⼀。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第⼀次取出来的version值进行比对，如果数据库表当前版本号与第⼀次取出来的version值相等，则予以更新，否则认为是过期数据。
   - 常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。

[REF：小林coding|互斥锁与自旋锁](https://xiaolincoding.com/os/4_process/pessim_and_optimi_lock.html#%E4%BA%92%E6%96%A5%E9%94%81%E4%B8%8E%E8%87%AA%E6%97%8B%E9%94%81)

## 讲一下协程

协程是用户态的轻量级线程，是线程内部调度的基本单位。

同一个时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理。

- ==协程是由用户代码控制的，而不是由操作系统内核调度==。它不依赖操作系统提供的线程管理机制，因此可以在用户空间实现，并避免线程切换的**开销**；

- 可以在==一个线程内执行多个协程==，并且可以通过协程之间的切换来实现任务并发。这种切换是协作式的，也就是一个协程在执行过程中可以==**主动让出执行权**==给其他协程。

  **协程作用**

  1. 异步编程：简化异步任务的调度和等待，使代码看起来像是顺序执行的。传统的异步编程通常涉及回调函数，这可能会导致回调地狱（Callback Hell）；
  2. 状态机：协程能够暂停和恢复执行，保留函数的上下文状态，从而能够编写具有复杂状态转换逻辑的代码，而无序显式地编写状态机的逻辑；
  3. 生成器：协程可以作为生成器（Generator）使用，通过逐步生成数据而不是一次性生成所有数据。对于处理大量数据或按需计算的数据非常有用
  4. 轻量级线程：协程是一种轻量级的并发机制，可以用于`并发任务的调度和执行`。与线程相比，协程的创建和`切换开销较小`，且协程通常在同一线程内运行，避免了线程间的上下文切换开销。也`减少`了由于共享状态引起的`线程安全`问题。

## 什么是QPS和TPS，如何计算

- QPS是每秒查询率，值一台服务器每秒能响应的查询次数，用于衡量特定的查询服务器在规定事件内处理流量的多少，是主要针对专门用于查询服务器的性能指标；
  - QPS = 1s/单个请求耗时 * 服务器核心数（线程数）
- TPS是每秒事务数，一个事务市值客户端向服务器发送请求然后服务器做出反应的过程
  - TPS = 事务的数量 / 执行的事件

## 如何根据CPU利⽤率动态设计，优化线程池

11





